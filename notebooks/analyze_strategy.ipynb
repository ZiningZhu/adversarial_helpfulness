{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Persuasion strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "from pathlib import Path \n",
    "import matplotlib.pyplot as plt \n",
    "import json\n",
    "\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ecqa/secondbest</th>\n",
       "      <th colspan=\"3\" halign=\"left\">nli/contra_to_neutral</th>\n",
       "      <th colspan=\"3\" halign=\"left\">nli/entail_to_neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explainer</th>\n",
       "      <th>chat</th>\n",
       "      <th>claude</th>\n",
       "      <th>gpt4</th>\n",
       "      <th>chat</th>\n",
       "      <th>claude</th>\n",
       "      <th>gpt4</th>\n",
       "      <th>chat</th>\n",
       "      <th>claude</th>\n",
       "      <th>gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>confidence manipulation</th>\n",
       "      <td>0.386</td>\n",
       "      <td>0.650</td>\n",
       "      <td>0.382</td>\n",
       "      <td>0.653333</td>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.780000</td>\n",
       "      <td>0.686667</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.623333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>appeal to authority</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selective evidence</th>\n",
       "      <td>0.668</td>\n",
       "      <td>0.694</td>\n",
       "      <td>0.790</td>\n",
       "      <td>0.426667</td>\n",
       "      <td>0.476667</td>\n",
       "      <td>0.550000</td>\n",
       "      <td>0.456667</td>\n",
       "      <td>0.673333</td>\n",
       "      <td>0.526667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>logical fallacies</th>\n",
       "      <td>0.102</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.110</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.096667</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.173333</td>\n",
       "      <td>0.130000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>comparative advantage framing</th>\n",
       "      <td>0.824</td>\n",
       "      <td>0.794</td>\n",
       "      <td>0.898</td>\n",
       "      <td>0.216667</td>\n",
       "      <td>0.310000</td>\n",
       "      <td>0.373333</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.230000</td>\n",
       "      <td>0.326667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>reframing the question</th>\n",
       "      <td>0.532</td>\n",
       "      <td>0.572</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.936667</td>\n",
       "      <td>0.953333</td>\n",
       "      <td>0.926667</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.943333</td>\n",
       "      <td>0.923333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>selective fact presentation</th>\n",
       "      <td>0.694</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.672</td>\n",
       "      <td>0.506667</td>\n",
       "      <td>0.480000</td>\n",
       "      <td>0.490000</td>\n",
       "      <td>0.530000</td>\n",
       "      <td>0.366667</td>\n",
       "      <td>0.556667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>analogical evidence</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.020000</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>detailed scenario building</th>\n",
       "      <td>0.318</td>\n",
       "      <td>0.276</td>\n",
       "      <td>0.624</td>\n",
       "      <td>0.203333</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.243333</td>\n",
       "      <td>0.123333</td>\n",
       "      <td>0.266667</td>\n",
       "      <td>0.176667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>complex inference</th>\n",
       "      <td>0.044</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.044</td>\n",
       "      <td>0.053333</td>\n",
       "      <td>0.056667</td>\n",
       "      <td>0.086667</td>\n",
       "      <td>0.026667</td>\n",
       "      <td>0.070000</td>\n",
       "      <td>0.033333</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Task                          ecqa/secondbest                \\\n",
       "Explainer                                chat claude   gpt4   \n",
       "confidence manipulation                 0.386  0.650  0.382   \n",
       "appeal to authority                     0.030  0.026  0.046   \n",
       "selective evidence                      0.668  0.694  0.790   \n",
       "logical fallacies                       0.102  0.276  0.110   \n",
       "comparative advantage framing           0.824  0.794  0.898   \n",
       "reframing the question                  0.532  0.572  0.482   \n",
       "selective fact presentation             0.694  0.722  0.672   \n",
       "analogical evidence                     0.028  0.010  0.016   \n",
       "detailed scenario building              0.318  0.276  0.624   \n",
       "complex inference                       0.044  0.008  0.044   \n",
       "\n",
       "Task                          nli/contra_to_neutral                      \\\n",
       "Explainer                                      chat    claude      gpt4   \n",
       "confidence manipulation                    0.653333  0.620000  0.780000   \n",
       "appeal to authority                        0.003333  0.013333  0.013333   \n",
       "selective evidence                         0.426667  0.476667  0.550000   \n",
       "logical fallacies                          0.060000  0.096667  0.060000   \n",
       "comparative advantage framing              0.216667  0.310000  0.373333   \n",
       "reframing the question                     0.936667  0.953333  0.926667   \n",
       "selective fact presentation                0.506667  0.480000  0.490000   \n",
       "analogical evidence                        0.010000  0.020000  0.013333   \n",
       "detailed scenario building                 0.203333  0.300000  0.243333   \n",
       "complex inference                          0.053333  0.056667  0.086667   \n",
       "\n",
       "Task                          nli/entail_to_neutral                      \n",
       "Explainer                                      chat    claude      gpt4  \n",
       "confidence manipulation                    0.686667  0.673333  0.623333  \n",
       "appeal to authority                        0.010000  0.043333  0.003333  \n",
       "selective evidence                         0.456667  0.673333  0.526667  \n",
       "logical fallacies                          0.086667  0.173333  0.130000  \n",
       "comparative advantage framing              0.200000  0.230000  0.326667  \n",
       "reframing the question                     0.943333  0.943333  0.923333  \n",
       "selective fact presentation                0.530000  0.366667  0.556667  \n",
       "analogical evidence                        0.010000  0.040000  0.006667  \n",
       "detailed scenario building                 0.123333  0.266667  0.176667  \n",
       "complex inference                          0.026667  0.070000  0.033333  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_tasks = [\"ecqa/secondbest\", \"nli/contra_to_neutral\", \"nli/entail_to_neutral\"]\n",
    "models = [\"chat\", \"claude\", \"gpt4\"]\n",
    "strategies_v1 = [\"confidence manipulation\", \"appeal to authority\", \"selective evidence\", \"logical fallacies\", \"comparative advantage framing\", \"reframing the question\", \"selective fact presentation\", \"analogical evidence\", \"detailed scenario building\", \"complex inference\"]\n",
    "strategies_v2 = [str(id_) for id_ in range(1, 1+40)]\n",
    "# v2 there are 40 techniques. I'm using number to index them. Please refer to persuasion_strategy.py for the detailed list.\n",
    "\n",
    "def count_strategy_v1(dataset_task, model):\n",
    "\n",
    "    df = pd.read_csv(Path(f\"../data/{dataset_task}/{model}/with_nle_w_strategy_v1.csv\"))\n",
    "    \n",
    "    counter = {s:0 for s in strategies_v1}\n",
    "    total = len(df)\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            d = json.loads(row.strategy[7:-3])\n",
    "        except json.JSONDecodeError:\n",
    "            #print(\"Decode error. Here's the raw output\", row.strategy)\n",
    "            d = {}\n",
    "        for s in d:\n",
    "            if s.lower() not in counter:\n",
    "                pass \n",
    "                #print(s)\n",
    "            else:\n",
    "                counter[s.lower()] += 1\n",
    "    return [counter[s] / total for s in strategies_v1]\n",
    "\n",
    "def count_strategy_v2(dataset_task, model):\n",
    "    df = pd.read_csv(Path(f\"../data/{dataset_task}/{model}/with_nle_w_strategy.csv\"))\n",
    "    counter = {s:0 for s in strategies_v2}\n",
    "    total = len(df)\n",
    "    for i, row in df.iterrows():\n",
    "        try:\n",
    "            d = json.loads(row.strategy[7:-3])\n",
    "        except json.JSONDecodeError:\n",
    "            d = {}\n",
    "            print(\"Decode error. dataset_task={}, model={}\".format(dataset_task, model))\n",
    "        for s in d:\n",
    "            technique_id = s.split()[0].strip(\".\")\n",
    "            if technique_id not in counter:\n",
    "                pass \n",
    "            else:\n",
    "                counter[technique_id] += 1\n",
    "    return [counter[s] / total for s in strategies_v2]\n",
    "\n",
    "\n",
    "def count_strategy_collect_results(version=1):\n",
    "    \"\"\"\n",
    "    Output a table\n",
    "    \"\"\"\n",
    "    if version == 1:\n",
    "        n_strategies = 10\n",
    "        strategies = strategies_v1\n",
    "    else:\n",
    "        n_strategies = 40\n",
    "        strategies = strategies_v2\n",
    "    report_data = np.zeros((n_strategies, len(dataset_tasks) * len(models)))\n",
    "    for i, task in enumerate(dataset_tasks):\n",
    "        for j, model in enumerate(models):\n",
    "            if version == 1:\n",
    "                frequencies = count_strategy_v1(task, model)\n",
    "            else:\n",
    "                frequencies = count_strategy_v2(task, model)\n",
    "            report_data[:,i*len(models) + j] = frequencies \n",
    "    header = pd.MultiIndex.from_product([dataset_tasks, models], names=[\"Task\", \"Explainer\"])\n",
    "    df = pd.DataFrame(report_data, index=strategies, columns=header)\n",
    "    return df\n",
    "\n",
    "df = count_strategy_collect_results(version=1)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "Task & \\multicolumn{3}{l}{ecqa/secondbest} & \\multicolumn{3}{l}{nli/contra\\_to\\_neutral} & \\multicolumn{3}{l}{nli/entail\\_to\\_neutral} \\\\\n",
      "Explainer &            chat & claude & gpt4 &                  chat & claude & gpt4 &                  chat & claude & gpt4 \\\\\n",
      "\\midrule\n",
      "confidence manipulation       &            0.39 &   0.65 & 0.38 &                  0.65 &   0.62 & 0.78 &                  0.69 &   0.67 & 0.62 \\\\\n",
      "appeal to authority           &            0.03 &   0.03 & 0.05 &                  0.00 &   0.01 & 0.01 &                  0.01 &   0.04 & 0.00 \\\\\n",
      "selective evidence            &            0.67 &   0.69 & 0.79 &                  0.43 &   0.48 & 0.55 &                  0.46 &   0.67 & 0.53 \\\\\n",
      "logical fallacies             &            0.10 &   0.28 & 0.11 &                  0.06 &   0.10 & 0.06 &                  0.09 &   0.17 & 0.13 \\\\\n",
      "comparative advantage framing &            0.82 &   0.79 & 0.90 &                  0.22 &   0.31 & 0.37 &                  0.20 &   0.23 & 0.33 \\\\\n",
      "reframing the question        &            0.53 &   0.57 & 0.48 &                  0.94 &   0.95 & 0.93 &                  0.94 &   0.94 & 0.92 \\\\\n",
      "selective fact presentation   &            0.69 &   0.72 & 0.67 &                  0.51 &   0.48 & 0.49 &                  0.53 &   0.37 & 0.56 \\\\\n",
      "analogical evidence           &            0.03 &   0.01 & 0.02 &                  0.01 &   0.02 & 0.01 &                  0.01 &   0.04 & 0.01 \\\\\n",
      "detailed scenario building    &            0.32 &   0.28 & 0.62 &                  0.20 &   0.30 & 0.24 &                  0.12 &   0.27 & 0.18 \\\\\n",
      "complex inference             &            0.04 &   0.01 & 0.04 &                  0.05 &   0.06 & 0.09 &                  0.03 &   0.07 & 0.03 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/6nkzdmxs6hl7xl72dd7_m4cr0000gn/T/ipykernel_64699/58295077.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.to_latex(float_format=\"%.2f\"))\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decode error. dataset_task=ecqa/secondbest, model=claude\n",
      "Decode error. dataset_task=nli/contra_to_neutral, model=chat\n",
      "Decode error. dataset_task=nli/contra_to_neutral, model=claude\n",
      "Decode error. dataset_task=nli/entail_to_neutral, model=chat\n",
      "Decode error. dataset_task=nli/entail_to_neutral, model=chat\n",
      "Decode error. dataset_task=nli/entail_to_neutral, model=claude\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th>Task</th>\n",
       "      <th colspan=\"3\" halign=\"left\">ecqa/secondbest</th>\n",
       "      <th colspan=\"3\" halign=\"left\">nli/contra_to_neutral</th>\n",
       "      <th colspan=\"3\" halign=\"left\">nli/entail_to_neutral</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Explainer</th>\n",
       "      <th>chat</th>\n",
       "      <th>claude</th>\n",
       "      <th>gpt4</th>\n",
       "      <th>chat</th>\n",
       "      <th>claude</th>\n",
       "      <th>gpt4</th>\n",
       "      <th>chat</th>\n",
       "      <th>claude</th>\n",
       "      <th>gpt4</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.358</td>\n",
       "      <td>0.280</td>\n",
       "      <td>0.460</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.080000</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.016667</td>\n",
       "      <td>0.063333</td>\n",
       "      <td>0.073333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.610</td>\n",
       "      <td>0.580</td>\n",
       "      <td>0.782</td>\n",
       "      <td>0.103333</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.043333</td>\n",
       "      <td>0.213333</td>\n",
       "      <td>0.206667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.020</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.014</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.012</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.024</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.048</td>\n",
       "      <td>0.026</td>\n",
       "      <td>0.054</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.014</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.030</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.012</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.016</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.040</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.084</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>0.006</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>0.320</td>\n",
       "      <td>0.206</td>\n",
       "      <td>0.170</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.556667</td>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.410000</td>\n",
       "      <td>0.403333</td>\n",
       "      <td>0.716667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.458</td>\n",
       "      <td>0.424</td>\n",
       "      <td>0.318</td>\n",
       "      <td>0.446667</td>\n",
       "      <td>0.360000</td>\n",
       "      <td>0.676667</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>0.590000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.212</td>\n",
       "      <td>0.162</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.036667</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.030000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.043333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>0.094</td>\n",
       "      <td>0.108</td>\n",
       "      <td>0.150</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.344</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.532</td>\n",
       "      <td>0.126667</td>\n",
       "      <td>0.076667</td>\n",
       "      <td>0.263333</td>\n",
       "      <td>0.093333</td>\n",
       "      <td>0.040000</td>\n",
       "      <td>0.233333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.028</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.020</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.013333</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.003333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>0.018</td>\n",
       "      <td>0.064</td>\n",
       "      <td>0.016</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.006667</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>0.023333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.334</td>\n",
       "      <td>0.606</td>\n",
       "      <td>0.546</td>\n",
       "      <td>0.033333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.046667</td>\n",
       "      <td>0.060000</td>\n",
       "      <td>0.023333</td>\n",
       "      <td>0.086667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>0.030</td>\n",
       "      <td>0.140</td>\n",
       "      <td>0.038</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.003333</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.008</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>0.036</td>\n",
       "      <td>0.042</td>\n",
       "      <td>0.046</td>\n",
       "      <td>0.193333</td>\n",
       "      <td>0.210000</td>\n",
       "      <td>0.296667</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>0.220000</td>\n",
       "      <td>0.323333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.028</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>0.010</td>\n",
       "      <td>0.036</td>\n",
       "      <td>0.004</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>0.004</td>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>0.008</td>\n",
       "      <td>0.010</td>\n",
       "      <td>0.006</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>0.002</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Task      ecqa/secondbest               nli/contra_to_neutral            \\\n",
       "Explainer            chat claude   gpt4                  chat    claude   \n",
       "1                   0.358  0.280  0.460              0.063333  0.080000   \n",
       "2                   0.610  0.580  0.782              0.103333  0.220000   \n",
       "3                   0.020  0.028  0.014              0.000000  0.010000   \n",
       "4                   0.016  0.008  0.012              0.000000  0.000000   \n",
       "5                   0.036  0.024  0.030              0.000000  0.000000   \n",
       "6                   0.048  0.026  0.054              0.000000  0.003333   \n",
       "7                   0.014  0.016  0.030              0.000000  0.000000   \n",
       "8                   0.012  0.010  0.016              0.000000  0.003333   \n",
       "9                   0.002  0.000  0.002              0.000000  0.000000   \n",
       "10                  0.002  0.000  0.000              0.000000  0.000000   \n",
       "11                  0.008  0.002  0.004              0.000000  0.000000   \n",
       "12                  0.016  0.008  0.016              0.000000  0.000000   \n",
       "13                  0.040  0.036  0.084              0.000000  0.003333   \n",
       "14                  0.006  0.002  0.008              0.000000  0.000000   \n",
       "15                  0.002  0.000  0.002              0.000000  0.000000   \n",
       "16                  0.002  0.000  0.000              0.000000  0.000000   \n",
       "17                  0.004  0.000  0.000              0.000000  0.000000   \n",
       "18                  0.320  0.206  0.170              0.500000  0.556667   \n",
       "19                  0.458  0.424  0.318              0.446667  0.360000   \n",
       "20                  0.212  0.162  0.378              0.033333  0.036667   \n",
       "21                  0.094  0.108  0.150              0.000000  0.003333   \n",
       "22                  0.344  0.404  0.532              0.126667  0.076667   \n",
       "23                  0.028  0.042  0.020              0.000000  0.003333   \n",
       "24                  0.018  0.064  0.016              0.003333  0.000000   \n",
       "25                  0.334  0.606  0.546              0.033333  0.003333   \n",
       "26                  0.030  0.140  0.038              0.000000  0.003333   \n",
       "27                  0.002  0.004  0.008              0.000000  0.000000   \n",
       "28                  0.004  0.000  0.002              0.000000  0.000000   \n",
       "29                  0.002  0.000  0.000              0.000000  0.000000   \n",
       "30                  0.004  0.004  0.000              0.000000  0.000000   \n",
       "31                  0.036  0.042  0.046              0.193333  0.210000   \n",
       "32                  0.002  0.004  0.000              0.000000  0.000000   \n",
       "33                  0.004  0.010  0.000              0.000000  0.000000   \n",
       "34                  0.008  0.028  0.002              0.000000  0.000000   \n",
       "35                  0.010  0.036  0.004              0.000000  0.000000   \n",
       "36                  0.002  0.000  0.000              0.000000  0.000000   \n",
       "37                  0.004  0.002  0.000              0.000000  0.000000   \n",
       "38                  0.002  0.000  0.000              0.000000  0.000000   \n",
       "39                  0.008  0.010  0.006              0.000000  0.000000   \n",
       "40                  0.002  0.000  0.000              0.000000  0.000000   \n",
       "\n",
       "Task                nli/entail_to_neutral                      \n",
       "Explainer      gpt4                  chat    claude      gpt4  \n",
       "1          0.076667              0.016667  0.063333  0.073333  \n",
       "2          0.126667              0.043333  0.213333  0.206667  \n",
       "3          0.000000              0.000000  0.000000  0.006667  \n",
       "4          0.000000              0.000000  0.003333  0.000000  \n",
       "5          0.000000              0.000000  0.000000  0.003333  \n",
       "6          0.000000              0.000000  0.000000  0.003333  \n",
       "7          0.000000              0.000000  0.000000  0.003333  \n",
       "8          0.003333              0.000000  0.003333  0.003333  \n",
       "9          0.000000              0.000000  0.000000  0.000000  \n",
       "10         0.000000              0.000000  0.000000  0.000000  \n",
       "11         0.000000              0.000000  0.000000  0.000000  \n",
       "12         0.000000              0.000000  0.000000  0.003333  \n",
       "13         0.003333              0.000000  0.000000  0.000000  \n",
       "14         0.000000              0.000000  0.000000  0.000000  \n",
       "15         0.000000              0.000000  0.000000  0.000000  \n",
       "16         0.000000              0.000000  0.000000  0.000000  \n",
       "17         0.000000              0.000000  0.000000  0.000000  \n",
       "18         0.720000              0.410000  0.403333  0.716667  \n",
       "19         0.676667              0.333333  0.263333  0.590000  \n",
       "20         0.046667              0.030000  0.010000  0.043333  \n",
       "21         0.000000              0.000000  0.000000  0.006667  \n",
       "22         0.263333              0.093333  0.040000  0.233333  \n",
       "23         0.013333              0.006667  0.006667  0.003333  \n",
       "24         0.000000              0.006667  0.010000  0.023333  \n",
       "25         0.046667              0.060000  0.023333  0.086667  \n",
       "26         0.003333              0.003333  0.003333  0.000000  \n",
       "27         0.000000              0.000000  0.000000  0.000000  \n",
       "28         0.000000              0.000000  0.000000  0.000000  \n",
       "29         0.000000              0.000000  0.000000  0.000000  \n",
       "30         0.000000              0.000000  0.000000  0.000000  \n",
       "31         0.296667              0.200000  0.220000  0.323333  \n",
       "32         0.000000              0.000000  0.000000  0.000000  \n",
       "33         0.000000              0.000000  0.000000  0.000000  \n",
       "34         0.000000              0.000000  0.000000  0.000000  \n",
       "35         0.000000              0.000000  0.000000  0.000000  \n",
       "36         0.000000              0.000000  0.000000  0.000000  \n",
       "37         0.000000              0.000000  0.000000  0.000000  \n",
       "38         0.000000              0.000000  0.000000  0.000000  \n",
       "39         0.000000              0.000000  0.000000  0.000000  \n",
       "40         0.000000              0.000000  0.000000  0.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = count_strategy_collect_results(version=2)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{lrrrrrrrrr}\n",
      "\\toprule\n",
      "Task & \\multicolumn{3}{l}{ecqa/secondbest} & \\multicolumn{3}{l}{nli/contra\\_to\\_neutral} & \\multicolumn{3}{l}{nli/entail\\_to\\_neutral} \\\\\n",
      "Explainer &            chat & claude & gpt4 &                  chat & claude & gpt4 &                  chat & claude & gpt4 \\\\\n",
      "\\midrule\n",
      "1  &            0.36 &   0.28 & 0.46 &                  0.06 &   0.08 & 0.08 &                  0.02 &   0.06 & 0.07 \\\\\n",
      "2  &            0.61 &   0.58 & 0.78 &                  0.10 &   0.22 & 0.13 &                  0.04 &   0.21 & 0.21 \\\\\n",
      "3  &            0.02 &   0.03 & 0.01 &                  0.00 &   0.01 & 0.00 &                  0.00 &   0.00 & 0.01 \\\\\n",
      "4  &            0.02 &   0.01 & 0.01 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "5  &            0.04 &   0.02 & 0.03 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "6  &            0.05 &   0.03 & 0.05 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "7  &            0.01 &   0.02 & 0.03 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "8  &            0.01 &   0.01 & 0.02 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "9  &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "10 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "11 &            0.01 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "12 &            0.02 &   0.01 & 0.02 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "13 &            0.04 &   0.04 & 0.08 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "14 &            0.01 &   0.00 & 0.01 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "15 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "16 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "17 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "18 &            0.32 &   0.21 & 0.17 &                  0.50 &   0.56 & 0.72 &                  0.41 &   0.40 & 0.72 \\\\\n",
      "19 &            0.46 &   0.42 & 0.32 &                  0.45 &   0.36 & 0.68 &                  0.33 &   0.26 & 0.59 \\\\\n",
      "20 &            0.21 &   0.16 & 0.38 &                  0.03 &   0.04 & 0.05 &                  0.03 &   0.01 & 0.04 \\\\\n",
      "21 &            0.09 &   0.11 & 0.15 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.01 \\\\\n",
      "22 &            0.34 &   0.40 & 0.53 &                  0.13 &   0.08 & 0.26 &                  0.09 &   0.04 & 0.23 \\\\\n",
      "23 &            0.03 &   0.04 & 0.02 &                  0.00 &   0.00 & 0.01 &                  0.01 &   0.01 & 0.00 \\\\\n",
      "24 &            0.02 &   0.06 & 0.02 &                  0.00 &   0.00 & 0.00 &                  0.01 &   0.01 & 0.02 \\\\\n",
      "25 &            0.33 &   0.61 & 0.55 &                  0.03 &   0.00 & 0.05 &                  0.06 &   0.02 & 0.09 \\\\\n",
      "26 &            0.03 &   0.14 & 0.04 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "27 &            0.00 &   0.00 & 0.01 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "28 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "29 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "30 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "31 &            0.04 &   0.04 & 0.05 &                  0.19 &   0.21 & 0.30 &                  0.20 &   0.22 & 0.32 \\\\\n",
      "32 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "33 &            0.00 &   0.01 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "34 &            0.01 &   0.03 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "35 &            0.01 &   0.04 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "36 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "37 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "38 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "39 &            0.01 &   0.01 & 0.01 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "40 &            0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 &                  0.00 &   0.00 & 0.00 \\\\\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/5f/6nkzdmxs6hl7xl72dd7_m4cr0000gn/T/ipykernel_64699/58295077.py:1: FutureWarning: In future versions `DataFrame.to_latex` is expected to utilise the base implementation of `Styler.to_latex` for formatting and rendering. The arguments signature may therefore change. It is recommended instead to use `DataFrame.style.to_latex` which also contains additional functionality.\n",
      "  print(df.to_latex(float_format=\"%.2f\"))\n"
     ]
    }
   ],
   "source": [
    "print(df.to_latex(float_format=\"%.2f\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "transformers4",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
